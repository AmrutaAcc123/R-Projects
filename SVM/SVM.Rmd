---
title: "SVM"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
---

Clear Env Variables

```{r}

rm(list = ls(all=TRUE))

```

## Agenda 

* Read in the data

* Data Pre-processing

* Build a linear SVM model

* Do cross validation for finding the optimal C value

* Build SVM with Kernels

* Report Metrics of the various Models on Test Data

# Reading & Understanding the Data

```{r}

cancer_data <- read.csv("cancer_diagnosis.csv")

```

* Get a feel for the data using the str() function 

```{r}

str(cancer_data)

```

The dataset has 569 observations with 32 variables, the descriptions of the variables are given below :

1) **id** : Unique identification number of the sample

2) **Cancer** : This column represents whether the patient has a benign/normal tumor (0) or a cancerous one ("1")

3) **The remaining 30 variables** are real valued measurements some of which are given below:

	* radius (mean of distances from center to points on the perimeter)
	* texture (standard deviation of gray-scale values)
	* perimeter
	* area
	* smoothness (local variation in radius lengths)
	* compactness (perimeter^2 / area - 1.0)
	* concavity (severity of concave portions of the contour)
	* concave points (number of concave portions of the contour)
	* symmetry 
	* fractal dimension ("coastline approximation" - 1)
	

* Let's look at the head and tail of the dataset

```{r}

head(cancer_data)

tail(cancer_data)

```

# Data Pre-processing

* Let's convert the Cancer column into a factor, because it was read in as a numeric attribute (1 is if the patient has cancer and 0 is if the patient does not have cancer)

```{r}

cancer_data$Cancer <- as.factor(cancer_data$Cancer)

```

* Let's now remove the irrelevant column of "id" from the dataset

```{r}

cancer_data <- cancer_data[ , !(colnames(cancer_data) %in% "id")]

```

* Let's verify if there are any missing values in the dataset

```{r}

sum(is.na(cancer_data))

```

* Split the dataset into train and test using using stratified sampling using the caret package

```{r}

library(caret)

set.seed(1234)

index_train <- createDataPartition(cancer_data$Cancer, p = 0.7, list = F)

pre_train <- cancer_data[index_train, ]

pre_test <- cancer_data[-index_train, ]

```

* Standardize all the real valued variables in the dataset as it provides numerical stability to the svm solution

```{r}

std_method <- preProcess(pre_train, method = c("center", "scale"))

train_data <- predict(std_method, pre_train)
  
test_data <- predict(std_method, pre_test)

```


# Building Multiple SVM models

* Let's first start out building a linear SVM and tune the model to get a decent C value

## Linear SVM

* We can build the most basic linear SVM, with default parameters using the svm() function from the e1071 package

```{r}

library(e1071)

model_svm <- svm(Cancer ~ . , train_data, kernel = "linear")

summary(model_svm)

```


### Tuning for the optimal C

* One way to tune models, is first using an exponential search space and then doing a more refined search near the optimal area

```{r}

library(caret)

sampling_strategy <- trainControl(method = "repeatedcv", number = 4, repeats = 10)

svm_rough_model_c <- train(Cancer ~ . , train_data, method = "svmLinear",
                     tuneGrid = data.frame(.C = c(10^-4, 10^-3, 10^-2, 10^-1, 10^1, 10^2, 10^3)), trControl = sampling_strategy)

svm_rough_model_c

```

```{r}

svm_fine_model_c <- train(Cancer ~ . , train_data, method = "svmLinear",
                     tuneGrid = data.frame(.C = c(10^-0.25, 10^-0.5, 10^-0.75, 10^-1, 10^-1.25, 10^-1.5, 10^-1.75)), trControl = sampling_strategy, metric = "Accuracy")

svm_fine_model_c

```

* Hence, from the above cross validation experiment, we can choose the C parameter that gives us the best cross validation accuracy


* Let's measure the performance of our optimized svm on the test data 

```{r}

preds_svm <- predict(model_svm, test_data)

preds_svm_optimized <- predict(svm_fine_model_c, test_data)

confusionMatrix(preds_svm, test_data$Cancer)

confusionMatrix(preds_svm_optimized, test_data$Cancer)

```

data: http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/
