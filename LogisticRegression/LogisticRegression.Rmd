---
title: "Prediction of Term Deposit Subscription"
data_url : "https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r}

rm(list = ls(all=TRUE))

```

# Agenda 

* Get the data

* Data Pre-processing

* Build a model

* Predictions

* Communication

# Reading & Understanding the Data

```{r}
bank_data <- read.table("bank.txt", header=T, sep=";")

```


## Data Description

* The dataset is from a bank, using which we have to predict whether the subject subscribes to a term deposit or not

* The dataset has the following attributes:

1 - age (numeric)

2 - job : type of job (categorical: "admin.","unknown","unemployed","management","housemaid","entrepreneur","student",
                                    "blue-collar","self-employed","retired","technician","services") 

3 - marital : marital status (categorical: "married","divorced","single"; note: "divorced" means divorced or widowed)

4 - education (categorical: "unknown","secondary","primary","tertiary")

5 - default: has credit in default? (binary: "yes","no")

6 - balance: average yearly balance, in euros (numeric) 

7 - housing: has housing loan? (binary: "yes","no")

8 - loan: has personal loan? (binary: "yes","no")

9 - contact: contact communication type (categorical: "unknown","telephone","cellular") 

10 - day: last contact day of the month (numeric)

11 - month: last contact month of year (categorical: "jan", "feb", "mar", ..., "nov", "dec")

12 - duration: last contact duration, in seconds (numeric)

13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)

14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)
  
15 - previous: number of contacts performed before this campaign and for this client (numeric)

16 - poutcome: outcome of the previous marketing campaign (categorical: "unknown","other","failure","success")

__Response Variable (desired target):__

17 - y - has the client subscribed to a __term deposit?__ (binary: "yes","no")

## Understand the data

* The dataset has 4521 observations and 17 variables

```{r}

str(bank_data)

```


* Use the summary() function to understand the distribution of variables in the dataset

```{r}

summary(bank_data)

```

```{r}

head(bank_data)

tail(bank_data)

```


# Data Pre-processing

## Missing Values

* Missing Data

```{r}

sum(is.na(bank_data))

```

## Train/Test Split

```{r}

library(caret)

set.seed(123)

train_rows <- createDataPartition(bank_data$y, p = 0.7, list = F)

train_data <- bank_data[train_rows, ]

test_data <- bank_data[-train_rows, ]

```

```{r}

str(train_data)

```

# Build a model

## Basic Logistic Regression Model

```{r}

log_reg <- glm(y~., data = train_data, family = binomial)


```


* Summary

```{r}
summary(log_reg)
```



# ROC

## Predicted Values are between 0 and 1

* The predict() function on the "glm" object of "binomial" family gives a probability score between 0 and 1, NOT the original levels (0 and 1) of the response variable 

* Hence we must first choose a cutoff point for getting to the original levels of the response variables

* To choose the cutoff point we will use the train data, as test data should not be used to make any decisions regarding the model

## Creating an ROC plot

```{r}

prob_train <- predict(log_reg, type = "response")

library(ROCR)

pred <- prediction(prob_train, train_data$y)


```

```{r}

perf <- performance(pred, measure="tpr", x.measure="fpr")

```


```{r}

plot(perf, col=rainbow(10), colorize=T, print.cutoffs.at=seq(0,1,0.05))

```

* Extract the AUC score of the ROC curve and store it in a variable named "auc"

```{r}

perf_auc <- performance(pred, measure="auc")

# Access the auc score from the performance object

auc <- perf_auc@y.values[[1]]

print(auc)

```

## Choose a Cutoff Value

* Based on the trade off between TPR and FPR depending on the business domain, a call on the cutoff has to be made.


## Predictions on test data

* After choosing a cutoff value of 0.1, let's predict the class labels on the test data using our model

```{r}

prob_test <- predict(log_reg, test_data, type = "response")

preds_test <- ifelse(prob_test > 0.1, "yes", "no")


```


# Evaluation Metrics for classification


### Confusion Matrix

* Create a confusion matrix using the table() function

```{r}

test_data_labs <- test_data$y

conf_matrix <- table(test_data_labs, preds_test)

print(conf_matrix)

```

### Specificity

* The Proportion of correctly identified negatives by the test/model.

$${Specificity} = \frac{Number~of~True~Negatives}{Number~of~True~Negatives + Number~of~False~Positives}$$

```{r}

specificity <- conf_matrix[1, 1]/sum(conf_matrix[1, ])

print(specificity)

```


### Sensitivity

* The Proportion of correctly identified positives by the test/model.

$${Sensitivity} = \frac{Number~of~True~Positives}{Number~of~True~Positives + Number~of~False~Negatives}$$

```{r}

sensitivity <- conf_matrix[2, 2]/sum(conf_matrix[2, ])

print(sensitivity)

```

### Accuracy

* The Proportion of correctly identified psotivies/negatives in the entire population by the test/model

$${Accuracy} = \frac{Number~of~True~Positives +Number~of~True~Negatives}{Number~Of~Subjects~in~the~Population}$$

```{r}

accuracy <- sum(diag(conf_matrix))/sum(conf_matrix)

print(accuracy)

```

## Automated Computation

```{r}

library(caret)
confusionMatrix(as.factor(preds_test), as.factor(test_data$y), positive = "yes")
```



